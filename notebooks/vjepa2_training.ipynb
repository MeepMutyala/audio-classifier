{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VJEPA2 Audio Classification Training\n",
        "\n",
        "This notebook trains a VJEPA2 model on the ESC-50 audio classification dataset.\n",
        "\n",
        "## Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository and setup\n",
        "!git clone https://github.com/your-username/audio-classifier.git\n",
        "!cd audio-classifier && git checkout main\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install librosa pandas tqdm\n",
        "\n",
        "print(\"‚úÖ Repository cloned and packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup repository and change directory\n",
        "import os\n",
        "os.chdir('/kaggle/working/audio-classifier')\n",
        "print(f\"Changed to directory: {os.getcwd()}\")\n",
        "print(\"‚úÖ Repository setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Add the vjepa2 src to Python path\n",
        "vjepa2_src = Path('/kaggle/working/audio-classifier/external_models/vjepa2/src')\n",
        "if vjepa2_src.exists() and str(vjepa2_src) not in sys.path:\n",
        "    sys.path.insert(0, str(vjepa2_src))\n",
        "\n",
        "# Import shared utilities\n",
        "sys.path.append('/kaggle/working/audio-classifier/notebooks')\n",
        "from shared_utils import create_dataloaders, AudioTrainer\n",
        "\n",
        "# Import the VJEPA2 model\n",
        "from models.vjepa_audio import VJEPA2AudioClassifier\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup dataset path\n",
        "esc50_path = '/kaggle/working/audio-classifier/data/ESC-50'\n",
        "\n",
        "# Check if dataset exists\n",
        "if not Path(esc50_path).exists():\n",
        "    print(\"‚ùå ESC-50 dataset not found! Please ensure the dataset is in the correct location.\")\n",
        "    print(f\"Expected path: {esc50_path}\")\n",
        "else:\n",
        "    print(\"‚úÖ ESC-50 dataset found!\")\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader, val_loader, test_loader, num_classes = create_dataloaders(\n",
        "        esc50_path=esc50_path,\n",
        "        model_type='tubelet',  # VJEPA2 uses tubelet format\n",
        "        batch_size=16,  # Moderate batch size for VJEPA2\n",
        "        num_workers=2,\n",
        "        augment=True,\n",
        "        augment_factor=2\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Data loaders created!\")\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "    print(f\"Train batches: {len(train_loader)}\")\n",
        "    print(f\"Val batches: {len(val_loader)}\")\n",
        "    print(f\"Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "config = {\n",
        "    'num_classes': num_classes,\n",
        "    'img_size': (128, 157),  # (n_mels, time_frames)\n",
        "    'patch_size': 16,        # Good for audio patches\n",
        "    'num_frames': 16,        # Captures temporal context\n",
        "    'tubelet_size': 2,       # Small tubelets for audio\n",
        "    'embed_dim': 384,        # Reduced from video-optimized 768\n",
        "    'depth': 8,              # Sufficient for audio classification\n",
        "    'num_heads': 8           # Matches embed_dim/48 ratio\n",
        "}\n",
        "\n",
        "# Create model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VJEPA2AudioClassifier(**config)\n",
        "\n",
        "print(f\"‚úÖ Model created on {device}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Test model with a sample batch\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_batch = next(iter(train_loader))\n",
        "    sample_data, sample_target = sample_batch\n",
        "    sample_data = sample_data.to(device)\n",
        "    \n",
        "    output = model(sample_data)\n",
        "    print(f\"‚úÖ Model test successful!\")\n",
        "    print(f\"Input shape: {sample_data.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "training_config = {\n",
        "    'epochs': 50,\n",
        "    'lr': 0.001,\n",
        "    'save_path': '/kaggle/working/vjepa2_best.pth'\n",
        "}\n",
        "\n",
        "# Create trainer\n",
        "trainer = AudioTrainer(model, train_loader, val_loader, device=device)\n",
        "\n",
        "print(\"üöÄ Starting VJEPA2 training...\")\n",
        "print(f\"Expected time: 2-3 hours\")\n",
        "print(f\"GPU memory usage: ~10GB\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Start training\n",
        "trainer.train(\n",
        "    epochs=training_config['epochs'],\n",
        "    lr=training_config['lr'],\n",
        "    save_path=training_config['save_path']\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚úÖ VJEPA2 training completed!\")\n",
        "print(f\"Best model saved to: {training_config['save_path']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model and test\n",
        "if Path(training_config['save_path']).exists():\n",
        "    model.load_state_dict(torch.load(training_config['save_path'], map_location=device))\n",
        "    print(\"‚úÖ Best model loaded for testing\")\n",
        "    \n",
        "    # Test on test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "    \n",
        "    test_accuracy = 100. * correct / total\n",
        "    print(f\"üéØ Test Accuracy: {test_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"‚ùå No saved model found for testing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä VJEPA2 Training Results Summary\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Model: VJEPA2 Audio Classifier\")\n",
        "print(f\"Dataset: ESC-50\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Training epochs: {training_config['epochs']}\")\n",
        "print(f\"Learning rate: {training_config['lr']}\")\n",
        "print(f\"Batch size: {train_loader.batch_size}\")\n",
        "if 'test_accuracy' in locals():\n",
        "    print(f\"Test accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"Model saved to: {training_config['save_path']}\")\n",
        "print(\"\\n‚úÖ Training completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
